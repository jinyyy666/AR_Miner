{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: App-Review Miner\n",
    "Team members: Shanshan Li, Yingyezhe Jin, Tianshu Chu, Xiao Huang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Put all import here\n",
    "import numpy as np\n",
    "import lda\n",
    "import lda.datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP based preprocessing\n",
    "\n",
    "    Inputs:  datasetName\n",
    "             rmStopWords control to remove stop words\n",
    "             rmRareWords control to remove rarely occured words\n",
    "             \n",
    "    Outputs: trainSet    is a list of training reviews\n",
    "             testSet     is a list of testing reviews\n",
    "             unlabelSet  is a list of unlabeld reviews\n",
    "             vocabulary  is the corresponding n vocabulary in a dictionary form {word, index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size for templerun2 : 5527\n",
      "Training set Size: 1000\n",
      "Testing set Size: 2000\n",
      "Unlabeling set Size: 57559\n"
     ]
    }
   ],
   "source": [
    "%run ./AR_util.py\n",
    "%run ./AR_reviewInstance.py\n",
    "datasetName = \"templerun2\" # four apps : facebook, templerun2, swiftkey, tapfish\n",
    "\n",
    "rmStopWords = False # Removing stop words lead to information loss and bad f-score\n",
    "rmRareWords = True\n",
    "\n",
    "# trainSet/testSet/unlabel: dictionary of {label, reviews} for review data\n",
    "# vocabulary: dictionary len = V and the positional index of each term in the doc vector\n",
    "# set skParse True to directly read of the data that has been filtered out\n",
    "skParse = False\n",
    "if(skParse == False):\n",
    "    # the vocabulary is the words on the training set!\n",
    "    trainSet, testSet, unlabelSet, vocabulary = AR_parse(datasetName, rmStopWords, rmRareWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes based filtering\n",
    "\n",
    "    Inputs:  train/test/unlabelSet   are the preprocessed reviews \n",
    "             vocabulary              is the corresponding vocabulary of the reviews\n",
    "    Outputs: informMat    is a k*m np sparse matrix, k is the number of informative reviews, m is the length of vocabulary\n",
    "             informRev    is a list of informative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F-Score for the test data: 0.837037037037\n",
      "Number of informative reviews: 14684\n"
     ]
    }
   ],
   "source": [
    "%run ./AR_classifier.py\n",
    "# 1. Use the EM-NB or SVM to filter out the informative reviews\n",
    "# informMat: the informative reviews in X x V sparse matrix from, X: documents size, V: vocabulary size\n",
    "# informRev: corresponding reviews wrapped as a list of review instances\n",
    "useSVM = True # SVM is way better than emnb in terms of the testing. \n",
    "               # But it may not filter out the information effectively\n",
    "if(skParse == False):\n",
    "    if(useSVM == False):\n",
    "        informRev, informMat = AR_emnb(trainSet, testSet, unlabelSet, vocabulary, datasetName)\n",
    "    else:\n",
    "        informRev, informMat = AR_svm(trainSet, testSet, unlabelSet, vocabulary, datasetName)\n",
    "\n",
    "    # write the result back to the file (optional)\n",
    "    AR_writeReviews(informRev, datasetName)\n",
    "else:\n",
    "    # directly read from the file\n",
    "    informRev, informMat, vocabulary = AR_loadReviews(datasetName)\n",
    "\n",
    "print(\"Number of informative reviews: \" + str(len(informRev)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### LDA topic clustering\n",
    "\n",
    "    Inputs:  informMat  is the k*m np sparse matrix, k is the number of informative reviews, m  is the length of vocabulary\n",
    "             informRev  is the informative review list\n",
    "             vocabulary is the corresponding vocabulary dictionary\n",
    "             n_topics   is the number of topics\n",
    "    Outputs: doc_topic  is a k*n_topics np matrix, which indicates the probability\n",
    "             vocab      is the vocabulary in the list form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lda:n_documents: 14684\n",
      "INFO:lda:vocab_size: 5527\n",
      "INFO:lda:n_words: 238165\n",
      "INFO:lda:n_topics: 20\n",
      "INFO:lda:n_iter: 1500\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "INFO:lda:<0> log likelihood: -2449937\n",
      "INFO:lda:<500> log likelihood: -1531270\n",
      "INFO:lda:<1000> log likelihood: -1529038\n",
      "INFO:lda:<1499> log likelihood: -1529411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: it i time and close to forc\n",
      "Topic 1: is the a game that but onli\n",
      "Topic 2: t it won even the doesn i\n",
      "Topic 3: on my lag it galaxi phone s\n",
      "Topic 4: it a but game lag good s\n",
      "Topic 5: i coin my and to all the\n",
      "Topic 6: on my it phone download not fix\n",
      "Topic 7: it i star 5 fix thi give\n",
      "Topic 8: fix the updat game it pleas but\n",
      "Topic 9: the to and more need of new\n",
      "Topic 10: run the templ but first it a\n",
      "Topic 11: i it but play game and wa\n",
      "Topic 12: the it screen to and then i\n",
      "Topic 13: the up power a and you it\n",
      "Topic 14: i the game when me save and\n",
      "Topic 15: the you and when a of on\n",
      "Topic 16: i coin the object and 000 have\n",
      "Topic 17: to the i and it turn when\n",
      "Topic 18: i to t it can you if\n",
      "Topic 19: the sensit to tilt need be is\n"
     ]
    }
   ],
   "source": [
    "%run ./AR_lda.py\n",
    "# 2. Use the LDA to do the grouping based on the topic\n",
    "# doc_topi : a k*n_topics np matrix, which indicates the probability of each review belongs to one of the topic\n",
    "# vocab: a list of vocabulary words\n",
    "n_topics = 20\n",
    "doc_topic, vocab = AR_lda(informRev, informMat, vocabulary, n_topics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndoc_topic = model.doc_topic_\\nClustNum = []\\n# print doc_topic[1]\\nfor i in range(k):\\n    ClustNum.append(doc_topic[i].argmax())\\nprint ClustNum\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "doc_topic = model.doc_topic_\n",
    "ClustNum = []\n",
    "# print doc_topic[1]\n",
    "for i in range(k):\n",
    "    ClustNum.append(doc_topic[i].argmax())\n",
    "print ClustNum\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Ranking all the groups based on importance\n",
    "\n",
    "    Inputs:  \n",
    "    Outputs: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "calc_volume() takes exactly 2 arguments (1 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-770b1f916ef7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'run ./AR_ranker.py'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mwg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgroup_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgroup_rank\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc_topic\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minformRev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\chutianshu\\Documents\\Courses\\InformationRetrieval\\Project\\AR_ranker.py\u001b[0m in \u001b[0;36mgroup_rank\u001b[0;34m(matrix, wg, reviews)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mfg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mvolume\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalc_volume\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcalc_volume\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvolume\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcalc_average_rating\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreviews\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvolume\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: calc_volume() takes exactly 2 arguments (1 given)"
     ]
    }
   ],
   "source": [
    "%run ./AR_ranker.py\n",
    "wg = [0.5, 0.5]\n",
    "group_scores = group_rank(doc_topic, wg, informRev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Ranking all the reviews in each group based on text rank\n",
    "\n",
    "    Inputs:  \n",
    "    Outputs: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code here"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
