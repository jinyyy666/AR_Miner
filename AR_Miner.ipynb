{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: App-Review Miner\n",
    "Team members: Shanshan Li, Yingyezhe Jin, Tianshu Chu, Xiao Huang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Put all import here\n",
    "import numpy as np\n",
    "import lda\n",
    "import lda.datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP based preprocessing\n",
    "\n",
    "    Inputs:  datasetName\n",
    "             rmStopWords control to remove stop words\n",
    "             rmRareWords control to remove rarely occured words\n",
    "             \n",
    "    Outputs: trainSet    is a list of training reviews\n",
    "             testSet     is a list of testing reviews\n",
    "             unlabelSet  is a list of unlabeld reviews\n",
    "             vocabulary  is the corresponding n vocabulary in a dictionary form {word, index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size for templerun2 : 5527\n",
      "Training set Size: 1000\n",
      "Testing set Size: 2000\n",
      "Unlabeling set Size: 57559\n"
     ]
    }
   ],
   "source": [
    "%run ./AR_util.py\n",
    "%run ./AR_reviewInstance.py\n",
    "datasetName = \"templerun2\" # four apps : facebook, templerun2, swiftkey, tapfish\n",
    "\n",
    "rmStopWords = False # Removing stop words lead to information loss and bad f-score\n",
    "rmRareWords = True\n",
    "\n",
    "# trainSet/testSet/unlabel: dictionary of {label, reviews} for review data\n",
    "# vocabulary: dictionary len = V and the positional index of each term in the doc vector\n",
    "# set skParse True to directly read of the data that has been filtered out\n",
    "skParse = False\n",
    "if(skParse == False):\n",
    "    # the vocabulary is the words on the training set!\n",
    "    trainSet, testSet, unlabelSet, vocabulary = AR_parse(datasetName, rmStopWords, rmRareWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes based filtering\n",
    "\n",
    "    Inputs:  train/test/unlabelSet   are the preprocessed reviews \n",
    "             vocabulary              is the corresponding vocabulary of the reviews\n",
    "    Outputs: informMat    is a k*m np sparse matrix, k is the number of informative reviews, m is the length of vocabulary\n",
    "             informRev    is a list of informative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F-Score for the test data: 0.837037037037\n",
      "Number of informative reviews: 14684\n"
     ]
    }
   ],
   "source": [
    "%run ./AR_classifier.py\n",
    "# 1. Use the EM-NB or SVM to filter out the informative reviews\n",
    "# informMat: the informative reviews in X x V sparse matrix from, X: documents size, V: vocabulary size\n",
    "# informRev: corresponding reviews wrapped as a list of review instances\n",
    "useSVM = True # SVM is way better than emnb in terms of the testing. \n",
    "               # But it may not filter out the information effectively\n",
    "if(skParse == False):\n",
    "    if(useSVM == False):\n",
    "        informRev, informMat = AR_emnb(trainSet, testSet, unlabelSet, vocabulary, datasetName)\n",
    "    else:\n",
    "        informRev, informMat = AR_svm(trainSet, testSet, unlabelSet, vocabulary, datasetName)\n",
    "\n",
    "    # write the result back to the file (optional)\n",
    "    AR_writeReviews(informRev, datasetName)\n",
    "else:\n",
    "    # directly read from the file\n",
    "    informRev, informMat, vocabulary = AR_loadReviews(datasetName)\n",
    "\n",
    "print(\"Number of informative reviews: \" + str(len(informRev)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### LDA topic clustering\n",
    "\n",
    "    Inputs:  informMat  is the k*m np sparse matrix, k is the number of informative reviews, m  is the length of vocabulary\n",
    "             informRev  is the informative review list\n",
    "             vocabulary is the corresponding vocabulary dictionary\n",
    "             n_topics   is the number of topics\n",
    "    Outputs: doc_topic  is a k*n_topics np matrix, which indicates the probability\n",
    "             vocab      is the vocabulary in the list form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lda:n_documents: 14684\n",
      "INFO:lda:vocab_size: 5527\n",
      "INFO:lda:n_words: 238165\n",
      "INFO:lda:n_topics: 20\n",
      "INFO:lda:n_iter: 1500\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "INFO:lda:<0> log likelihood: -2449521\n",
      "INFO:lda:<500> log likelihood: -1530662\n",
      "INFO:lda:<1000> log likelihood: -1530186\n",
      "INFO:lda:<1499> log likelihood: -1531980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: it i to close and download time\n",
      "Topic 1: it but game a lag is sometim\n",
      "Topic 2: it i me play t game my\n",
      "Topic 3: i and coin the for have but\n",
      "Topic 4: run the templ but first i it\n",
      "Topic 5: the i when game and me save\n",
      "Topic 6: on my it phone galaxi not work\n",
      "Topic 7: it star i fix 5 thi but\n",
      "Topic 8: you to have if that a can\n",
      "Topic 9: the up power you a and when\n",
      "Topic 10: the is that onli a of problem\n",
      "Topic 11: the updat on fix game lag it\n",
      "Topic 12: the it screen to and then i\n",
      "Topic 13: coin object the i 000 have but\n",
      "Topic 14: i coin my and to all game\n",
      "Topic 15: the and but a more game new\n",
      "Topic 16: t i can it doesn the don\n",
      "Topic 17: the to i and when turn jump\n",
      "Topic 18: a it to but time take game\n",
      "Topic 19: to the sensit tilt need be is\n"
     ]
    }
   ],
   "source": [
    "%run ./AR_lda.py\n",
    "# 2. Use the LDA to do the grouping based on the topic\n",
    "# doc_topi : a k*n_topics np matrix, which indicates the probability of each review belongs to one of the topic\n",
    "# vocab: a list of vocabulary words\n",
    "n_topics = 20\n",
    "doc_topic, vocab = AR_lda(informRev, informMat, vocabulary, n_topics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc_topic = model.doc_topic_\n",
    "ClustNum = []\n",
    "# print doc_topic[1]\n",
    "for i in range(k):\n",
    "    ClustNum.append(doc_topic[i].argmax())\n",
    "print ClustNum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Ranking all the groups based on importance\n",
    "\n",
    "    Inputs:  \n",
    "    Outputs: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Cluster the reviews using volume and use TextRank to rank each instance\n",
    "\n",
    "    Inputs:  doc_topic  is a np matrix k*n_topic, where k is # of reviews\n",
    "             informRev  is a list of all informative reviews\n",
    "    Outputs: rankedInstance is a dict = {topic, list of ranked reviews with the score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In construct the graph of reviews ---- Nodes: 1021 Edges: 38072\n",
      "In construct the graph of reviews ---- Nodes: 1012 Edges: 21804\n",
      "In construct the graph of reviews ---- Nodes: 894 Edges: 37456\n",
      "In construct the graph of reviews ---- Nodes: 503 Edges: 3184\n",
      "In construct the graph of reviews ---- Nodes: 751 Edges: 4436\n",
      "In construct the graph of reviews ---- Nodes: 834 Edges: 20164\n",
      "In construct the graph of reviews ---- Nodes: 803 Edges: 11438\n",
      "In construct the graph of reviews ---- Nodes: 592 Edges: 6674\n",
      "In construct the graph of reviews ---- Nodes: 672 Edges: 1214\n",
      "In construct the graph of reviews ---- Nodes: 617 Edges: 5092\n",
      "In construct the graph of reviews ---- Nodes: 595 Edges: 1742\n",
      "In construct the graph of reviews ---- Nodes: 625 Edges: 3630\n",
      "In construct the graph of reviews ---- Nodes: 1043 Edges: 35468\n",
      "In construct the graph of reviews ---- Nodes: 567 Edges: 7974\n",
      "In construct the graph of reviews ---- Nodes: 805 Edges: 5196\n",
      "In construct the graph of reviews ---- Nodes: 726 Edges: 2752\n",
      "In construct the graph of reviews ---- Nodes: 501 Edges: 3704\n",
      "In construct the graph of reviews ---- Nodes: 819 Edges: 6036\n",
      "In construct the graph of reviews ---- Nodes: 597 Edges: 5080\n",
      "In construct the graph of reviews ---- Nodes: 707 Edges: 14232\n"
     ]
    }
   ],
   "source": [
    "%run ./AR_textrank.py\n",
    "AR_tfIdf(informRev)\n",
    "rankedInstance = AR_textrank(doc_topic, informRev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance review for topic group: 0\n",
      "[(2829, 0.0010345541059186782), (4331, 0.0010345541059186782), (1137, 0.0010345541059186779), (8233, 0.0010345541059186775), (8510, 0.0010345541059186773), (8939, 0.0010345541059186773), (9388, 0.0010345541059186773), (615, 0.0010345541059186771), (1519, 0.0010345541059186771), (3660, 0.0010345541059186771)]\n",
      "Instance review for topic group: 1\n",
      "[(6882, 0.0010593220334581201), (4571, 0.0010593220334581199), (11393, 0.0010593220334581199), (13258, 0.0010593220334581199), (2417, 0.0010593220334581196), (3720, 0.0010593220334581196), (8428, 0.0010593220334581196), (12365, 0.0010593220334581196), (3109, 0.0010593220334581194), (6013, 0.0010593220334581194)]\n",
      "Instance review for topic group: 2\n",
      "[(3970, 0.0012181751711557894), (14265, 0.0012181751711557889), (45, 0.0012181751711557878), (753, 0.0012181751711557878), (12260, 0.0012181751711557876), (13207, 0.0012181751711557876), (3537, 0.0012181751711557874), (8642, 0.0012181751711557874), (5955, 0.0012181751711557872), (6661, 0.0012181751711557868)]\n",
      "Instance review for topic group: 3\n",
      "[(3398, 0.0026571010592567621), (5088, 0.0026571010592567621), (2000, 0.0026571010592567612), (3448, 0.0026571010592567612), (935, 0.0026571010592567608), (4692, 0.0026571010592567599), (6457, 0.0026571010592567599), (1441, 0.0026571010592567595), (6536, 0.0026571010592567595), (44, 0.002657101059256759)]\n",
      "Instance review for topic group: 4\n",
      "[(424, 0.0016441959688454472), (3164, 0.0016441959688454461), (10255, 0.0016441959688454461), (303, 0.001644195968845444), (8392, 0.001644195968845444), (2516, 0.0016441959688454435), (9740, 0.0016441959688454435), (10767, 0.0016441959688454435), (13399, 0.0016441959688454435), (620, 0.0016441959688454433)]\n",
      "Instance review for topic group: 5\n",
      "[(2166, 0.0012968486564040509), (4657, 0.0012968486564040504), (271, 0.0012968486564040502), (1525, 0.0012968486564040502), (13106, 0.0012968486564040502), (13456, 0.0012968486564040502), (692, 0.00129684865640405), (1662, 0.00129684865640405), (1976, 0.00129684865640405), (4087, 0.00129684865640405)]\n",
      "Instance review for topic group: 6\n",
      "[(7775, 0.0013449899113534788), (962, 0.0013449899113534784), (225, 0.0013449899113534781), (1365, 0.0013449899113534781), (2427, 0.0013449899113534781), (6650, 0.0013449899113534781), (603, 0.0013449899113534779), (2549, 0.0013449899113534779), (5361, 0.0013449899113534779), (6427, 0.0013449899113534779)]\n",
      "Instance review for topic group: 7\n",
      "[(9455, 0.00199580878689743), (13340, 0.00199580878689743), (1243, 0.0019958087868974296), (2952, 0.0019958087868974296), (2987, 0.0019958087868974296), (3317, 0.0019958087868974296), (3434, 0.0019958087868974296), (10012, 0.0019958087868974296), (13019, 0.0019958087868974296), (195, 0.0019958087868974291)]\n",
      "Instance review for topic group: 8\n",
      "[(1432, 0.0023501761705985299), (2382, 0.0023501761705985299), (13727, 0.0023501761705985291), (14388, 0.0023501761705985291), (2408, 0.0023501761705985286), (9167, 0.0023501761705985286), (9828, 0.0023501761705985286), (12200, 0.0023501761705985286), (12327, 0.0023501761705985286), (12953, 0.0023501761705985286)]\n",
      "Instance review for topic group: 9\n",
      "[(1321, 0.0019579050338738163), (3843, 0.0019579050338738154), (447, 0.0019579050338738141), (2517, 0.0019579050338738141), (3797, 0.0019579050338738141), (4766, 0.0019579050338738141), (5533, 0.0019579050338738141), (7678, 0.0019579050338738141), (8139, 0.0019579050338738141), (8723, 0.0019579050338738141)]\n",
      "Instance review for topic group: 10\n",
      "[(59, 0.0023250406515444868), (1399, 0.0023250406515444846), (3862, 0.0023250406515444846), (1369, 0.0023250406515444837), (1906, 0.0023250406515444837), (613, 0.0023250406515444833), (918, 0.0023250406515444833), (1107, 0.0023250406515444833), (1805, 0.0023250406515444833), (2655, 0.0023250406515444833)]\n",
      "Instance review for topic group: 11\n",
      "[(3113, 0.0018935807460237384), (5629, 0.0018935807460237384), (14427, 0.0018935807460237384), (12603, 0.0018935807460237373), (13679, 0.0018935807460237373), (88, 0.0018935807460237369), (8192, 0.0018935807460237369), (10223, 0.0018935807460237369), (12873, 0.0018935807460237369), (166, 0.0018935807460237367)]\n",
      "Instance review for topic group: 12\n",
      "[(12400, 0.00099865181988123769), (14408, 0.00099865181988123769), (2528, 0.00099865181988123748), (149, 0.00099865181988123726), (311, 0.00099865181988123726), (2401, 0.00099865181988123726), (238, 0.00099865181988123704), (4798, 0.00099865181988123704), (6553, 0.00099865181988123704), (6867, 0.00099865181988123704)]\n",
      "Instance review for topic group: 13\n",
      "[(4528, 0.0020387359796149554), (6836, 0.0020387359796149554), (7722, 0.0020387359796149554), (5838, 0.002038735979614955), (8027, 0.002038735979614955), (13772, 0.002038735979614955), (14347, 0.002038735979614955), (2972, 0.0020387359796149545), (5215, 0.0020387359796149545), (7052, 0.0020387359796149545)]\n",
      "Instance review for topic group: 14\n",
      "[(3972, 0.0015140045325747814), (5486, 0.0015140045325747814), (2525, 0.0015140045325747809), (4158, 0.0015140045325747809), (3682, 0.0015140045325747805), (4516, 0.0015140045325747803), (10899, 0.0015140045325747803), (3095, 0.0015140045325747801), (1866, 0.0015140045325747799), (3403, 0.0015140045325747799)]\n",
      "Instance review for topic group: 15\n",
      "[(7356, 0.0019219680540330756), (7005, 0.0019219680540330751), (1451, 0.0019219680540330747), (1555, 0.0019219680540330747), (6337, 0.0019219680540330747), (6577, 0.0019219680540330747), (9837, 0.0019219680540330747), (12630, 0.0019219680540330747), (991, 0.0019219680540330743), (1423, 0.0019219680540330743)]\n",
      "Instance review for topic group: 16\n",
      "[(391, 0.0024236548590370606), (1605, 0.0024236548590370606), (7965, 0.0024236548590370606), (384, 0.0024236548590370601), (499, 0.0024236548590370601), (14277, 0.0024236548590370601), (254, 0.0024236548590370597), (531, 0.0024236548590370597), (734, 0.0024236548590370597), (893, 0.0024236548590370597)]\n",
      "Instance review for topic group: 17\n",
      "[(3488, 0.0014251104408836469), (3147, 0.0014251104408836467), (5936, 0.0014251104408836465), (7216, 0.0014251104408836465), (3091, 0.0014251104408836463), (1380, 0.0014251104408836458), (12512, 0.0014251104408836458), (13227, 0.0014251104408836458), (318, 0.0014251104408836456), (1567, 0.0014251104408836456)]\n",
      "Instance review for topic group: 18\n",
      "[(1275, 0.0019056693557523885), (1552, 0.0019056693557523885), (1635, 0.0019056693557523885), (2001, 0.0019056693557523885), (3158, 0.0019056693557523885), (3268, 0.0019056693557523885), (3637, 0.0019056693557523885), (7038, 0.0019056693557523885), (7452, 0.0019056693557523885), (7554, 0.0019056693557523885)]\n",
      "Instance review for topic group: 19\n",
      "[(1280, 0.0015423767991936633), (91, 0.0015423767991936629), (1479, 0.0015423767991936629), (1464, 0.0015423767991936627), (6329, 0.0015423767991936627), (7422, 0.0015423767991936627), (7919, 0.0015423767991936627), (11372, 0.0015423767991936627), (12255, 0.0015423767991936627), (1201, 0.0015423767991936622)]\n"
     ]
    }
   ],
   "source": [
    "# print the top 10 reviews:\n",
    "for i in range(len(rankedInstance)):\n",
    "    print(\"Instance review for topic group: \" + str(i))\n",
    "    print(rankedInstance[i][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
