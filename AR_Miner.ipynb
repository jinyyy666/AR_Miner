{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: App-Review Miner\n",
    "Team members: Shanshan Li, Yingyezhe Jin, Tianshu Chu, Xiao Huang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Put all import here\n",
    "import numpy as np\n",
    "import lda\n",
    "import lda.datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP based preprocessing\n",
    "\n",
    "    Inputs:  raw_data        \n",
    "    Outputs: AllR      is an n*m np matrix, n is the number of total reviews, m is the length of vocabulary\n",
    "             vocab     is the corresponding n vocabulary list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes based filtering\n",
    "\n",
    "    Inputs:  AllR      is an n*m np matrix, n is the number of total reviews, m is the length of vocabulary\n",
    "    Outputs: InfoR     is a k*m np matrix, k is the number of informative reviews, m is the length of vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### LDA topic clustering\n",
    "\n",
    "    Inputs:  InfoR    is the k*m np matrix, k is the number of informative reviews, m is the length of vocabulary\n",
    "             vocab    is the corresponding n vocabulary list\n",
    "             n_topics is the number of topics\n",
    "    Outputs: doc_topi is a k*n_topics np matrix, which indicates the probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: british churchill sale million major letters west britain\n",
      "Topic 1: church government political country state people party against\n",
      "Topic 2: elvis king fans presley life concert young death\n",
      "Topic 3: yeltsin russian russia president kremlin moscow michael operation\n",
      "Topic 4: pope vatican paul john surgery hospital pontiff rome\n",
      "Topic 5: family funeral police miami versace cunanan city service\n",
      "Topic 6: simpson former years court president wife south church\n",
      "Topic 7: order mother successor election nuns church nirmala head\n",
      "Topic 8: charles prince diana royal king queen parker bowles\n",
      "Topic 9: film french france against bardot paris poster animal\n",
      "Topic 10: germany german war nazi letter christian book jews\n",
      "Topic 11: east peace prize award timor quebec belo leader\n",
      "Topic 12: n't life show told very love television father\n",
      "Topic 13: years year time last church world people say\n",
      "Topic 14: mother teresa heart calcutta charity nun hospital missionaries\n",
      "Topic 15: city salonika capital buddhist cultural vietnam byzantine show\n",
      "Topic 16: music tour opera singer israel people film israeli\n",
      "Topic 17: church catholic bernardin cardinal bishop wright death cancer\n",
      "Topic 18: harriman clinton u.s ambassador paris president churchill france\n",
      "Topic 19: city museum art exhibition century million churches set\n"
     ]
    }
   ],
   "source": [
    "# Inputs here\n",
    "InfoM = lda.datasets.load_reuters()\n",
    "vocab = lda.datasets.load_reuters_vocab()\n",
    "n_topics = 20\n",
    "# Code here\n",
    "model = lda.LDA(n_topics, n_iter=1500, random_state=1)\n",
    "model.fit(InfoM) \n",
    "topic_word = model.topic_word_\n",
    "n_top_words = 8\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(n_top_words+1):-1]\n",
    "    print('Topic {}: {}'.format(i, ' '.join(topic_words)))\n",
    "doc_topi = model.doc_topic_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.09492754  0.1673913   0.00072464  0.00072464  0.00072464  0.14565217\n",
      "  0.00072464  0.05144928  0.00072464  0.00072464  0.00797101  0.03695652\n",
      "  0.00072464  0.25434783  0.00072464  0.00072464  0.00072464  0.01521739\n",
      "  0.00797101  0.21086957]\n"
     ]
    }
   ],
   "source": [
    "doc_topic = model.doc_topic_\n",
    "print doc_topic[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Ranking all the groups based on importance\n",
    "\n",
    "    Inputs:  \n",
    "    Outputs: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Ranking all the reviews in each group based on text rank\n",
    "\n",
    "    Inputs:  \n",
    "    Outputs: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code here"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
